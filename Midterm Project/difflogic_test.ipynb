{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNYHH+Ji51Zm4PBRoUYi7Kl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","\n","def initialize_network(layers, neurons_per_layer):\n","    weights = []\n","    for layer in range(layers):\n","        layer_weights = [np.random.normal(0, 1, 3) for _ in range(neurons_per_layer)]\n","        weights.append(layer_weights)\n","    return weights\n","\n","def forward_propagation(inputs, weights, neuron_idx=None):\n","\n","    if neuron_idx is not None:\n","        a1 = inputs[neuron_idx % len(inputs)]\n","        a2 = inputs[(neuron_idx + 1) % len(inputs)]\n","    else:\n","        a1, a2 = inputs[0], inputs[1]\n","\n","    f = np.array([\n","        a1 * a2,\n","        a1 + a2 - a1 * a2,\n","        a1 + a2 - 2 * a1 * a2\n","    ])\n","\n","    exp_weights = np.exp(weights)\n","    p = exp_weights / np.sum(exp_weights)\n","\n","    a_prime = np.sum(p * f)\n","    return p, f, a_prime\n","\n","def cross_entropy_loss(a_prime, target):\n","    exp_a_prime = np.exp(a_prime)\n","    q1 = exp_a_prime / (1 + exp_a_prime)\n","    q0 = 1 / (1 + exp_a_prime)\n","\n","    loss = -(target * np.log(q1) + (1 - target) * np.log(q0))\n","    return loss, q0, q1\n","\n","def backward_propagation(p, f, q1, target, weights, learning_rate=0.1):\n","    dL_dq1 = q1 - target\n","    dq1_da_prime = q1 * (1 - q1)\n","    da_prime_dp = f\n","    dp_dweights = p * (1 - p)\n","\n","    gradients = dL_dq1 * dq1_da_prime * da_prime_dp * dp_dweights\n","\n","    updated_weights = weights - learning_rate * gradients\n","    return updated_weights\n","\n","def aggregate_outputs(outputs, neurons_per_class):\n","    num_classes = len(outputs) // neurons_per_class\n","    aggregated_outputs = []\n","    for i in range(num_classes):\n","        aggregated_output = np.sum(outputs[i * neurons_per_class:(i + 1) * neurons_per_class])\n","        aggregated_outputs.append(aggregated_output)\n","    return aggregated_outputs\n","\n","def train_network(inputs, targets, weights, layers, neurons_per_layer, neurons_per_class, epochs, learning_rate):\n","    for epoch in range(epochs):\n","        if (epoch+1)%1000 == 0:\n","          print(f\"Epoch {epoch + 1}/{epochs}\")\n","\n","        correct_predictions = 0\n","\n","        for data_idx, input_data in enumerate(inputs):\n","            if len(input_data) != 2:\n","                raise ValueError(\"Each input data point must have exactly 2 features.\")\n","\n","            layer_inputs = input_data\n","            all_layer_outputs = []\n","\n","            for layer in range(layers):\n","                layer_outputs = []\n","                for neuron_idx in range(neurons_per_layer):\n","                    p, f, a_prime = forward_propagation(layer_inputs, weights[layer][neuron_idx], neuron_idx)\n","                    layer_outputs.append(a_prime)\n","\n","                layer_inputs = layer_outputs\n","                all_layer_outputs.append(layer_outputs)\n","\n","            aggregated_outputs = aggregate_outputs(all_layer_outputs[-1], neurons_per_class)\n","            predicted_class = np.argmax(aggregated_outputs)\n","\n","            target = targets[data_idx]\n","            if predicted_class == target:\n","                correct_predictions += 1\n","\n","            for layer in reversed(range(layers)):\n","                for neuron_idx in range(neurons_per_layer):\n","                    p, f, a_prime = forward_propagation(layer_inputs, weights[layer][neuron_idx], neuron_idx)\n","                    loss, q0, q1 = cross_entropy_loss(a_prime, target)\n","                    weights[layer][neuron_idx] = backward_propagation(p, f, q1, target, weights[layer][neuron_idx], learning_rate)\n","\n","            if (epoch+1)%1000 == 0:\n","              print(f\"  Data {data_idx + 1}: Loss = {loss:.4f}, Aggregated Outputs = {aggregated_outputs}\")\n","\n","        accuracy = correct_predictions / len(inputs)\n","        if (epoch+1)%1000 == 0:\n","          print(f\"  Epoch {epoch + 1} Accuracy: {accuracy * 100:.2f}%\")\n","\n","    return weights\n","\n","def main():\n","    inputs = [\n","        [0.6, 0.8],\n","        [0.5, 0.1],\n","        [0.4, 0.9]\n","    ]\n","    targets = [1, 0, 1]\n","\n","    layers = 3\n","    neurons_per_layer = 6\n","    neurons_per_class = 3\n","\n","    weights = initialize_network(layers, neurons_per_layer)\n","\n","    epochs = 20000\n","    learning_rate = 0.99\n","    weights = train_network(inputs, targets, weights, layers, neurons_per_layer, neurons_per_class, epochs, learning_rate)\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sdrR-5B3KT5j","executionInfo":{"status":"ok","timestamp":1732623715890,"user_tz":-480,"elapsed":49221,"user":{"displayName":"陳國誌","userId":"03267140479007565050"}},"outputId":"68c7844d-89f6-4a83-c66b-e53a118c10c4"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1000/20000\n","  Data 1: Loss = 0.3800, Aggregated Outputs = [2.241493748523084, 2.3481197783826264]\n","  Data 2: Loss = 0.9048, Aggregated Outputs = [1.0532866096660811, 1.0859110992756276]\n","  Data 3: Loss = 0.3976, Aggregated Outputs = [2.080298035812442, 2.153858238557909]\n","  Epoch 1000 Accuracy: 66.67%\n","Epoch 2000/20000\n","  Data 1: Loss = 0.3980, Aggregated Outputs = [2.210902553649812, 2.0433796098163164]\n","  Data 2: Loss = 0.8254, Aggregated Outputs = [1.07987683226977, 0.7259726274795679]\n","  Data 3: Loss = 0.4184, Aggregated Outputs = [2.065260013280466, 1.8103533833286312]\n","  Epoch 2000 Accuracy: 33.33%\n","Epoch 3000/20000\n","  Data 1: Loss = 0.4167, Aggregated Outputs = [2.2101193227981324, 2.0419483946240735]\n","  Data 2: Loss = 0.7885, Aggregated Outputs = [1.075726271272849, 0.6545345823626353]\n","  Data 3: Loss = 0.4393, Aggregated Outputs = [2.079565706786124, 1.801135666931407]\n","  Epoch 3000 Accuracy: 33.33%\n","Epoch 4000/20000\n","  Data 1: Loss = 0.4187, Aggregated Outputs = [2.1921828788051516, 2.1005743353537474]\n","  Data 2: Loss = 0.8009, Aggregated Outputs = [1.0400329147421834, 0.6982220935950898]\n","  Data 3: Loss = 0.4397, Aggregated Outputs = [2.0693068461380397, 1.8661069035939504]\n","  Epoch 4000 Accuracy: 33.33%\n","Epoch 5000/20000\n","  Data 1: Loss = 0.4079, Aggregated Outputs = [2.1384779141677512, 2.234939248982994]\n","  Data 2: Loss = 0.8417, Aggregated Outputs = [0.9471938282857426, 0.8758125816887132]\n","  Data 3: Loss = 0.4250, Aggregated Outputs = [2.015600220205248, 2.0458659373409875]\n","  Epoch 5000 Accuracy: 100.00%\n","Epoch 6000/20000\n","  Data 1: Loss = 0.3997, Aggregated Outputs = [2.102602939875612, 2.298029579178545]\n","  Data 2: Loss = 0.8615, Aggregated Outputs = [0.8544040954128709, 1.016626449058132]\n","  Data 3: Loss = 0.4144, Aggregated Outputs = [1.9818227553381904, 2.1584560784986264]\n","  Epoch 6000 Accuracy: 66.67%\n","Epoch 7000/20000\n","  Data 1: Loss = 0.3964, Aggregated Outputs = [2.1023506264153284, 2.2757631901063196]\n","  Data 2: Loss = 0.8666, Aggregated Outputs = [0.8464559379388659, 1.0134061461540296]\n","  Data 3: Loss = 0.4101, Aggregated Outputs = [1.9762978513862004, 2.1380597562078307]\n","  Epoch 7000 Accuracy: 66.67%\n","Epoch 8000/20000\n","  Data 1: Loss = 0.3936, Aggregated Outputs = [2.132571513423031, 2.196897220133793]\n","  Data 2: Loss = 0.8705, Aggregated Outputs = [0.896557816647878, 0.9555388452595031]\n","  Data 3: Loss = 0.4074, Aggregated Outputs = [2.0033604992776746, 2.0487687029919526]\n","  Epoch 8000 Accuracy: 66.67%\n","Epoch 9000/20000\n","  Data 1: Loss = 0.3975, Aggregated Outputs = [2.1451296652044642, 2.1644250929377464]\n","  Data 2: Loss = 0.8633, Aggregated Outputs = [0.9216164203584973, 0.9331451095928922]\n","  Data 3: Loss = 0.4122, Aggregated Outputs = [2.020505848534242, 2.018347458034527]\n","  Epoch 9000 Accuracy: 33.33%\n","Epoch 10000/20000\n","  Data 1: Loss = 0.3985, Aggregated Outputs = [2.149045784360241, 2.156823882158778]\n","  Data 2: Loss = 0.8613, Aggregated Outputs = [0.9279860913223463, 0.9280819062257177]\n","  Data 3: Loss = 0.4135, Aggregated Outputs = [2.0260777654942266, 2.01161987529679]\n","  Epoch 10000 Accuracy: 33.33%\n","Epoch 11000/20000\n","  Data 1: Loss = 0.3988, Aggregated Outputs = [2.1498339637433914, 2.155517440214412]\n","  Data 2: Loss = 0.8608, Aggregated Outputs = [0.929096911564329, 0.9271579301164085]\n","  Data 3: Loss = 0.4138, Aggregated Outputs = [2.0272863961700027, 2.0105727780392013]\n","  Epoch 11000 Accuracy: 66.67%\n","Epoch 12000/20000\n","  Data 1: Loss = 0.3988, Aggregated Outputs = [2.150005441247996, 2.1552797612993837]\n","  Data 2: Loss = 0.8607, Aggregated Outputs = [0.9292797205186031, 0.9269481432338097]\n","  Data 3: Loss = 0.4139, Aggregated Outputs = [2.02755267362212, 2.0103950228307017]\n","  Epoch 12000 Accuracy: 66.67%\n","Epoch 13000/20000\n","  Data 1: Loss = 0.3988, Aggregated Outputs = [2.1500625913673916, 2.155241974859789]\n","  Data 2: Loss = 0.8607, Aggregated Outputs = [0.9292836934576792, 0.9268922241176064]\n","  Data 3: Loss = 0.4139, Aggregated Outputs = [2.0276268822672985, 2.010369968854236]\n","  Epoch 13000 Accuracy: 66.67%\n","Epoch 14000/20000\n","  Data 1: Loss = 0.3988, Aggregated Outputs = [2.1500950363036617, 2.1552420589747046]\n","  Data 2: Loss = 0.8607, Aggregated Outputs = [0.9292583262819492, 0.9268679882151407]\n","  Data 3: Loss = 0.4139, Aggregated Outputs = [2.0276585032658385, 2.0103714228771437]\n","  Epoch 14000 Accuracy: 66.67%\n","Epoch 15000/20000\n","  Data 1: Loss = 0.3988, Aggregated Outputs = [2.1501202008328573, 2.1552481209364336]\n","  Data 2: Loss = 0.8607, Aggregated Outputs = [0.9292310441361168, 0.926851611388566]\n","  Data 3: Loss = 0.4139, Aggregated Outputs = [2.027679170226217, 2.0103762602920754]\n","  Epoch 15000 Accuracy: 66.67%\n","Epoch 16000/20000\n","  Data 1: Loss = 0.3988, Aggregated Outputs = [2.15014168485139, 2.1552545655544]\n","  Data 2: Loss = 0.8607, Aggregated Outputs = [0.9292061385251641, 0.9268382945890842]\n","  Data 3: Loss = 0.4139, Aggregated Outputs = [2.0276958035567936, 2.0103810546383536]\n","  Epoch 16000 Accuracy: 66.67%\n","Epoch 17000/20000\n","  Data 1: Loss = 0.3988, Aggregated Outputs = [2.1501605339254564, 2.1552604473946007]\n","  Data 2: Loss = 0.8607, Aggregated Outputs = [0.929183970586509, 0.9268267868922437]\n","  Data 3: Loss = 0.4139, Aggregated Outputs = [2.027710151880761, 2.010385345774702]\n","  Epoch 17000 Accuracy: 66.67%\n","Epoch 18000/20000\n","  Data 1: Loss = 0.3988, Aggregated Outputs = [2.1501772602856843, 2.155265686826972]\n","  Data 2: Loss = 0.8607, Aggregated Outputs = [0.9291642360846444, 0.9268166371534573]\n","  Data 3: Loss = 0.4139, Aggregated Outputs = [2.0277228243499765, 2.010389144034365]\n","  Epoch 18000 Accuracy: 66.67%\n","Epoch 19000/20000\n","  Data 1: Loss = 0.3988, Aggregated Outputs = [2.1501922129183537, 2.1552703541317335]\n","  Data 2: Loss = 0.8607, Aggregated Outputs = [0.9291465797801739, 0.926807597202858]\n","  Data 3: Loss = 0.4139, Aggregated Outputs = [2.0277341368510458, 2.0103925199446238]\n","  Epoch 19000 Accuracy: 66.67%\n","Epoch 20000/20000\n","  Data 1: Loss = 0.3988, Aggregated Outputs = [2.1502056610717353, 2.155274531276556]\n","  Data 2: Loss = 0.8607, Aggregated Outputs = [0.9291306952381733, 0.9267994912792321]\n","  Data 3: Loss = 0.4139, Aggregated Outputs = [2.027744305497441, 2.010395538303888]\n","  Epoch 20000 Accuracy: 66.67%\n"]}]},{"cell_type":"code","source":["    np.random.normal(0, 1, 3)\n","\n","    print(\"q0: \", round(q0, 2))\n","    print(\"q1: \", round(q1, 2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":165},"id":"i-VEYOgCcZyP","executionInfo":{"status":"error","timestamp":1732533805185,"user_tz":-480,"elapsed":576,"user":{"displayName":"陳國誌","userId":"03267140479007565050"}},"outputId":"2445b7be-7097-4be6-efdd-2b93e6e71bd7"},"execution_count":71,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'q0' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-71-fe54b4c22692>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"q0: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"q1: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'q0' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"JIpttG6mDyDd"},"execution_count":null,"outputs":[]}]}